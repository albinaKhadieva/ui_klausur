<!DOCTYPE html>
<html lang="de">
    <head>
        <meta charset="utf-8">
        <title>KI Home</title>
        <link rel="stylesheet" href="../css/style.css">
        <link rel="stylesheet" href="../css/text.css">
        <link rel="icon" type="image/x-icon" href="../bilder/icontitle.svg">
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="KI, Maschine learning, Technologie, Digital">
        <meta name="author" content="Albina, Christian, Haubir">
        <meta name="copyright" content="Gr 2">
        <meta name="keyword" content="AI, KI, Maschinlernen, Maschine lerning, Technologie, Digital, ChtGPT">
        <meta name="robots" content="follow">
    </head>

    <body>
        <header>
            <div class="container header">
                <label for="burger" id="burger-label"><img src="../bilder/burger-bar.png" id="burger-bar"></label>
                <input type="checkbox" id="burger">
                <div class="header_top" id="header">
                    <a href="../index.html" id="logo_link"><img src="../bilder/logo.svg" alt="logo" id="logo"><svg width="200" height="200" xmlns="http://www.w3.org/2000/svg">
                        <title>Gruppe2</title>
                        <g id="Layer_1">
                         <title>Layer 1</title>
                         <path id="svg_28" d="m516.72152,524.84388l-18.45992,6.11814l3.48101,-4.85232l14.9789,-1.26582l0.00001,0z" opacity="NaN" stroke="#00bfbf" fill="none"/>
                         <path id="svg_29" d="m501.21519,525.47679c0.52743,0.63291 6.22363,2.21519 8.75527,1.47679c2.53165,-0.7384 -10.97046,3.48101 -11.07595,3.48101c0.10549,0 2.8481,-4.32489 2.32068,-4.95781l0,0.00001z" opacity="NaN" stroke="#00bfbf" fill="none"/>
                         <g id="svg_5">
                          <g stroke="null" id="svg_33" stroke-width="5">
                           <path stroke="#ffffff" id="svg_3" d="m22.86552,84.16136l-16.73316,24.70652c0.15973,0.15973 -0.47952,5.59317 2.07741,5.91277c2.55693,0.31962 14.87939,4.0396 12.94447,3.67566c-1.93489,-0.36394 7.83048,-0.79914 5.59317,-6.23259" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_4" d="m17.47858,116.69833l-3.67549,10.7072c0.15973,0.15973 36.07214,13.02458 33.13783,1.53616" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_6" d="m73.41117,113.50219l-8.15008,26.68792c0.15973,0.15973 -4.95413,13.58352 -11.02679,16.77969c-6.07269,3.19614 -17.22462,6.82841 -21.21382,7.87718c-3.98921,1.04877 -8.91693,2.14718 -14.58301,-1.00243c-5.66608,-3.14961 -2.96351,-11.79742 -1.34512,-15.51336" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_7" d="m16.64706,149.20202l3.03258,-5.29981l-2.96351,-4.44529l-2.66718,-4.14893l4.44607,-5.97708" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_9" d="m71.24483,118.71231l83.86756,-25.78261" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_10" d="m72.1339,116.63785l5.33433,-17.18842c0,0 4.77617,-7.4088 13.07401,-7.70515" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_11" d="m89.32229,91.7443l76.16244,-22.52275" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_12" d="m104.77553,86.70633l2.66718,-17.18842c0,0 2.37082,-5.33433 7.70515,-5.63069" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_13" d="m113.62315,64.18358l63.71564,-20.15192" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_14" d="m59.68711,59.73829l96.31436,-29.33883" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_15" d="m25.97906,48.77327l57.49227,-16.5957c0,0 6.2234,-1.77811 10.07597,1.77811c3.85258,3.55622 10.37231,10.66866 10.66866,11.55773" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_16" d="m94.36027,111.30351l11.26137,11.85408c0,0 5.63069,5.03798 10.37231,2.07447" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_17" d="m129.9225,121.34144l-15.11395,4.44529" opacity="NaN" fill="none"/>
                           <ellipse stroke="#ffffff" opacity="NaN" ry="8.5942" rx="8.5942" id="svg_18" cy="119.00867" cx="137.03494" fill="none"/>
                           <ellipse stroke="#ffffff" opacity="NaN" ry="8.5942" rx="8.5942" id="svg_19" cy="90.55888" cx="162.5212" fill="none"/>
                           <ellipse stroke="#ffffff" opacity="NaN" ry="8.5942" rx="8.5942" id="svg_20" cy="66.85073" cx="173.48621" fill="none"/>
                           <ellipse stroke="#ffffff" opacity="NaN" ry="8.5942" rx="8.5942" id="svg_21" cy="41.95719" cx="185.63665" fill="none"/>
                           <ellipse stroke="#ffffff" opacity="NaN" ry="8.5942" rx="8.5942" id="svg_22" cy="27.43595" cx="164.00297" fill="none"/>
                           <path stroke="#ffffff" id="svg_23" d="m22.05043,84.92822l2.07447,-5.33433c0,0 -7.11244,-8.00151 -0.59271,-26.07897" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_24" d="m22.93948,54.70032c7.11244,-19.26288 30.2307,-38.08551 50.08347,-40.53116" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_25" d="m72.14939,14.11912c2.15209,0.46897 35.60254,-9.39406 62.8266,17.18842" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_26" d="m134.07143,30.1031c32.30234,29.63519 8.89055,56.6032 5.92704,60.45577" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_27" d="m127.25535,101.22756l13.92853,-11.55773" opacity="NaN" fill="none"/>
                           <path stroke="#ffffff" id="svg_30" d="m15.82703,94.41145l52.45427,-16.5957c0,0 -36.56853,7.75647 -40.74663,3.57081c-4.17811,-4.18567 -9.33684,11.8395 -11.70766,13.0249l0.00002,0z" opacity="NaN" fill="#ffffff"/>
                           <ellipse stroke="#ffffff" opacity="NaN" ry="8.5942" rx="8.5942" id="svg_31" cy="62.96512" cx="52.50856" fill="none"/>
                           <ellipse stroke="#ffffff" transform="matrix(2.68322 -0.832524 0.832524 2.68322 -63.123 20.1782)" opacity="NaN" ry="0.58017" rx="1.26582" id="svg_32" cy="33.49094" cx="42.4469" fill="none"/>
                          </g>
                          <text stroke="#ffffff" opacity="NaN" transform="matrix(1.8657 0 0 1.8657 -25.3548 60.6364)" xml:space="preserve" text-anchor="start" font-family="Noto Sans JP" font-size="24" stroke-width="2" id="svg_34" y="59.74291" x="53.74071" fill="#ffffff">Gr</text>
                          <text stroke="#ffffff" transform="matrix(3.0888 0 0 2.36952 -56.0845 5.57869)" xml:space="preserve" text-anchor="start" font-family="Noto Sans JP" font-size="24" id="svg_36" y="76.17576" x="58.18283" fill="#ffffff">2</text>
                         </g>
                        </g>
                       </svg></a>
                    <h1 class="header_slogan">KI - Von Nullen und Einsen zu bahnbrechender Intelligenz</h1>
                    <input type="text" class="header_input" placeholder="Search">
                </div>
    
                <nav class="header_nav">
                    <a href="../index.html"><button class="nav_btn">Home</button></a>
                    <a href="wasistki.html"><button class="nav_btn">Was ist KI?</button></a>
                    <a href="machinelearning.html"><button class="nav_btn">Machine Learning/ Deep Learning</button></a>
                    <a href="ethikki.html"><button class="nav_btn" active>Ethik & KI</button></a>
                    <a href="sozialeauswirkungen.html"><button class="nav_btn">Soziale Auswirkungen</button></a>
                    <a href="anwendungen.html"><button class="nav_btn">Anwendungen KI</button></a>
                    <a href="chatbot.html"><button class="nav_btn">Chatbot</button></a>
                </nav>
            </div>
        </header>
    <main>
        <div class="container">
			<article>
                <div class="div_main">
                    <div class="div_text">
                    <h1>Ethik der Künstlichen Intelligenz</h1>
                    <p>Die Ethik der künstlichen Intelligenz ist ein Teilbereich der angewandten Ethik, der sich mit den ethischen Fragen von KI-Systemen befasst.</p>

                    <h2>Themenbereiche der KI-Ethik</h2>
                    <ul>
                        <li>Die Rolle von KI-Systemen in der Gesellschaft und ethische Werte, die ihrem Einsatz zugrunde liegen.</li>
                        <li>Ethische Normen für Menschen, die künstlich intelligente Systeme entwerfen, herstellen, testen, zertifizieren und benutzen.</li>
                        <li>Ethisches Verhalten von KI-Systemen (Maschinenethik).</li>
                        <li>Konsequenzen einer sog. Singularität aufgrund einer superintelligenten KI.</li>
                    </ul>

                    <p>Die KI-Ethik hat Berührungspunkte und Überlappungen mit anderen Teilbereichen der angewandten Ethik: Digitale Ethik, Informationsethik, Medienethik, Virtuelle Ethik, Technikethik und Roboterethik.</p>

                    <p>Die wachsende Bedeutung der KI-Ethik ergibt sich aus der Tatsache, dass „Künstliche Intelligenz (KI) und Robotik … in naher Zukunft erhebliche Auswirkungen auf die Entwicklung der Menschheit haben werden. Sie haben grundlegende Fragen darüber aufgeworfen, was wir mit diesen Systemen tun sollten, was die Systeme selbst tun sollten, welche Risiken sie bergen und wie wir diese kontrollieren können.“ Dabei sind nicht die Auswirkungen der KI-Anwendung an sich Gegenstand der KI-Ethik, sondern die Frage, wann und unter welchen Bedingungen bestimmte Auswirkungen zulässig sind.</p>

                    <p>Die Debatte über ethische Fragen der KI begann bereits 1960 mit einer Arbeit von Norbert Wiener und der Erwiderung von Arthur L. Samuel.</p>

                    <h2>KI-Ethik als angewandte Ethik</h2>
                    <p>KI-Ethik ist ein junges Teilgebiet der angewandten Ethik. Wie in anderen Bereichen der angewandten Ethik lassen sich auch hier zwei unterschiedliche Herangehensweisen unterscheiden: einerseits ein prinzipienethischer Ansatz, der allgemeine Prinzipien für die Behandlung praktischer Probleme aufstellt, und andererseits ein partikularistischer Ansatz, der Moralurteile für konkrete Handlungssituationen entwickelt.</p>

                    <h3>Prinzipienethischer Ansatz</h3>
                    <p>Der prinzipienethische Ansatz (englisch principlism) wurde in den 1970er Jahren in der Medizinethik entwickelt und dient seitdem als Vorbild für die Entwicklung anderer Bereichsethiken, auch der KI-Ethik.</p>

                    <p>Bei diesem Ansatz wird ein Satz von Prinzipien bereitgestellt, aus denen sich moralische Urteile für konkrete Handlungssituationen ableiten lassen, daher auch die Bezeichnung deduktivistisches Modell. Die Prinzipien werden „dadurch begründet, dass sie eine Art Schnittmenge verschiedener normativer Konzeptionen darstellen“, so dass sie von den unterschiedlichen normativen Theorien unabhängig und mit jeder akzeptablen Ethik verträglich sind. Sie werden daher als Prinzipien mittlerer Reichweite (englisch mid-level-principles) bezeichnet und sollen außerdem an die moralischen Alltagsüberzeugungen (englisch common morality) anknüpfen. Es gibt hier kein oberstes Prinzip, das die Anwendung der anderen Prinzipien regelt, vielmehr kann es im konkreten Anwendungsfall durchaus Kollisionen zwischen den Prinzipien geben.</p>

                    <p>Die Anwendung der Prinzipien auf einen konkreten Fall ist keine einfache Herleitung, sondern sie verlangt einerseits eine genaue Beschreibung der Handlungsalternativen und andererseits eine sorgfältige Interpretation und Gewichtung der Prinzipien. Ziel ist ein Überlegungsgleichgewicht wie es John Rawls in seiner Theorie der Gerechtigkeit eingeführt hat. Das Überlegungsgleichgewicht liefert kein kategorisches Urteil, sondern eine sogenannte Prima-facie- oder Ceteris-paribus-Entscheidung. „Es wird in schwierigen Fällen nicht gelingen, ein für alle Mal richtige moralische Urteile zu fällen, sie sind vielmehr immer vorläufig (defeasible).“</p>

                    <h2>Partikularistischer Ansatz</h2></p>
                    <p>„Moralischer Partikularismus ist die Auffassung, dass der moralische Status einer Handlung nicht durch moralische Prinzipien bestimmt wird, sondern von der Konfiguration der moralisch relevanten Merkmale der Handlung in einem bestimmten Kontext abhängt. Die Hauptmotivation für den moralischen Partikularismus ergibt sich aus der Beobachtung, dass Ausnahmen von Prinzipien üblich und Ausnahmen von Ausnahmen nicht ungewöhnlich sind. Moralische Grundsätze, die nur für homogene Fälle geeignet sind, scheinen zu grob zu sein, um die feinen Nuancen in heterogenen moralischen Situationen zu berücksichtigen.“ Ob eine Eigenschaft ethisch für oder gegen eine Handlung spricht, hängt im allgemeinen von den anderen Eigenschaften und Randbedingungen der Handlung ab. Beim partikularistischen Ansatz werden konkrete Handlungsoptionen sorgfältig beschrieben und mit ähnlich gelagerten Fallbeispielen verglichen. Auch der partikularistische Ansatz greift auf ethische Prinzipien und Werte zurück. Andere Bezeichnungen für diesen Ansatz sind rekonstruktives Modell oder kasuistischer Ansatz.</p>

                    <h2>Ethische Prinzipien der künstlichen Intelligenz</h2></p>
                    <p>Eine Analyse von 84 Dokumenten mit ethischen Prinzipien und Richtlinien für KI, die überwiegend zwischen 2016 und 2019 veröffentlicht wurden, identifizierte 11 übergreifende ethische Prinzpien. Nach der Häufigkeit ihres Auftretens geordnet sind dies:</p>

                    <li>Transparenz, Erklärbarkeit, Interpretierbarkeit.</li>
                    <li>Gerechtigkeit, Fairness, Gleichheit, Inklusion, Pluralität, Vermeidung informationeller Voreingenommenheit (englisch bias).</li>
                    <li>Schadensvermeidung, keine Diskriminierung.</li>
                    <li>Verantwortung und Rechenschaftspflicht.</li>
                    <li>Schutz der Privatsphäre, Datenschutz und Datensicherheit.</li>
                    <li>Gemeinwohl, Schaffung sozioökonomischer Chancen und wirtschaftlichen Wohlstands.</li>
                    <li>Freiheit und Autonomie, Meinungsfreiheit, informationelle Selbstbestimmung, freie Wahl der Plattform und Technologie, Schutz vor technologischen Experimenten, Manipulation und Überwachung.</li>
                    <li>Vertrauen, vertrauenswürdige KI-Forschung, KI-Technologie und Designprinzipien.</li>
                    <li>Nachhaltigkeit.</li>
                    <li>Würde als Vorrecht des Menschen respektieren, bewahren und stärken.</li>
                    <li>Solidarität, Auswirkungen von KI auf den Arbeitsmarkt und den sozialen Zusammenhalt, Nutzbarkeit der KI für alle Glieder der Gesellschaft.</li>

                    <p>Luciano Floridi und Josh Cowls warnen davor, dass die Vielzahl unterschiedlicher KI-Regelwerke eher zu Verwirrung führt und dass ein „Markt für Prinzipien entsteht, auf dem Interessenten versucht sein könnten, sich die attraktivsten herauszupicken.“ Ihre Analyse von sechs hochrangigen Initiativen für gesellschaftlich nützlichen Einsatz von KI ergab eine weitgehende Übereinstimmung der ethischen Prinzipien, so dass es nach ihrer Ansicht möglich ist, die KI-Ethik auf die vier Prinzipien der Medizinethik und ein zusätzliches fünftes Prinzip Erklärbarkeit zu gründen:</p>

                    <li>Fürsorge (Benefizienz): KI-Technologie soll der Menschheit nützen, das Wohlergehen fördern, die Menschenwürde wahren und der Erhaltung des Planeten dienen.</li>
                    <li>Schadensvermeidung (Non-Malefizienz): Negative Folgen eines übermäßigen oder missbräuchlichen Einsatzes von KI müssen vermieden werden, KI soll nur in einem sicheren Rahmen eingesetzt werden.</li>
                    <li>Autonomie: Menschen müssen die volle Entscheidungsfreiheit darüber haben, ob und welche Aufgaben sie an KI-Systeme delegieren, ihre Freiheit, sich eigene Normen und Standards zu setzen, muss gewahrt bleiben.</li>
                    <li>Gerechtigkeit: Wahrung der Solidarität, Vermeidung von Ungerechtigkeit, gleichberechtigter Zugang zu den Vorteilen der KI.</li>
                    <li>Erklärbarkeit (Verständlichkeit): Die Prinzipien 1 bis 4 sind nur realisierbar, wenn auch Laien nachvollziehen können, welchen Nutzen oder Schaden KI für die Gesellschaft hat und wer für welche Auswirkungen verantwortlich ist.</li>
                    <p>Siehe auch: Explainable Artificial Intelligence</p>
                    <!-- Weitere Textabschnitte einfügen -->
                    <a href="#header"><button id="oben_btn">&uarr; Nach oben</button></a>
                </div>
                <div class="div_bild">
                    <img src="../bilder/Ethik&Ki.png" alt="Ethik und KI">
                </div>
            </div>
        </div>
		</article>
    </main>
    <footer>
        <!-- ... -->
		<div class="container footer">
                <nav class="footer_nav">
                    <a href="../html/impressum.html" class="footer_link">Impressum</a>
                    <a href="../html/datenschutz.html" class="footer_link">Datenschutz</a>
                    <a href="../html/kontakt.html" class="footer_link">Kontakt</a>
                </nav>
                <div class="footer_copy">
                    &copy; Gruppe 2, 2023
                </div>
            </div>
    </footer>
</body>
</html>
